import os
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from google.colab import drive
from google.colab import files
from keras.preprocessing import image
drive.mount('/content/drive')
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array
from helper_functions import plot_history, random_class_visualization, augmented_image_visualization
# base_model = '/content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'
# Inisialisasi base model yang akan kita gunakan
pre_trained_model = tf.keras.applications.inception_v3.InceptionV3(
    input_shape = (150, 150, 3),
    include_top = False)

# Freeze layers dari base_model
for layer in pre_trained_model.layers:
    layer.trainable = False
pre_trained_model.summary()
# Memilih mixed7 sebagai layer terakhir pada base model
last_layer = pre_trained_model.get_layer('mixed7')
print('Last layer output shape: ', last_layer.output.shape) # Get the shape from the output tensor
last_output = last_layer.output
# Flatten output menjadi 1 dimensi
x = tf.keras.layers.Flatten()(last_output)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)
# Final layers dengan softmax
x = tf.keras.layers.Dense  (10, activation='softmax')(x)

# Menambahkan lapisan jaringan ke dalam base_model
model = tf.keras.Model(pre_trained_model.input, x)

model.summary()
base_dir= '/content/drive/MyDrive/Bangkit_Fruits'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')
class_names = ["apple","banana","grapes", "kiwi", "lemon", "mango", "orange", "pear", "pineapple", "watermelon"]
random_class_visualization(class_names, validation_dir)
# Mempersiapkan train_dataset
train_dataset = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    image_size=(150, 150),
    batch_size=20,
    label_mode='categorical',
    )

# Mempersiapkan validation_dataset
validation_dataset = tf.keras.utils.image_dataset_from_directory(
    validation_dir,
    image_size=(150, 150),
    batch_size=20,
    label_mode='categorical'
    )
# Menentukan Function Preprocess
def preprocess(image, label):
    image = tf.keras.applications.inception_v3.preprocess_input(image)
    return image, label

# Menerapkan Function Preprocess ke dalam dataset
train_dataset_scaled = train_dataset.map(preprocess)
validation_dataset_scaled = validation_dataset.map(preprocess)
# Optimize dataset untuk training data
SHUFFLE_BUFFER_SIZE = 1000
PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE

train_dataset_final = (train_dataset_scaled
                       .cache()
                       .shuffle(SHUFFLE_BUFFER_SIZE)
                       .prefetch(PREFETCH_BUFFER_SIZE)
                       )

validation_dataset_final = (validation_dataset_scaled
                            .cache()
                            .prefetch(PREFETCH_BUFFER_SIZE)
                            )
# Create a model with data augmentation layers
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.4),
    tf.keras.layers.RandomTranslation(0.2,0.2),
    tf.keras.layers.RandomContrast(0.4),
    tf.keras.layers.RandomZoom(0.2),
    ])
# Masukkan data augmentation ke dalam model
inputs = tf.keras.Input(shape=(150, 150, 3))
x = data_augmentation(inputs)
x = model(x)

model_with_aug = tf.keras.Model(inputs, x)
# Mengatur parameter pelatihan
model_with_aug.compile(
    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001),
    loss = 'categorical_crossentropy',
    metrics = ['accuracy'])
class EarlyStoppingCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs['accuracy']>0.95:
            self.model.stop_training = True
            print("\nReached 95% accuracy so cancelling training!")
EPOCHS = 20

# Pelatihan Model
history = model_with_aug.fit(
    train_dataset_final,
    validation_data = validation_dataset_final,
    epochs = EPOCHS,
    verbose = 1,
    callbacks=[EarlyStoppingCallback()],)
def plot_loss_acc(history):
    '''Plots the training and validation loss and accuracy from a history object'''
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(len(acc))

    fig, ax = plt.subplots(1,2, figsize=(12, 6))
    ax[0].plot(epochs, acc, 'bo', label='Training accuracy')
    ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')
    ax[0].set_title('Training and validation accuracy')
    ax[0].set_xlabel('epochs')
    ax[0].set_ylabel('accuracy')
    ax[0].legend()

    ax[1].plot(epochs, loss, 'bo', label='Training Loss')
    ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')
    ax[1].set_title('Training and validation loss')
    ax[1].set_xlabel('epochs')
    ax[1].set_ylabel('loss')
    ax[1].legend()

    plt.show()

plot_loss_acc(history)
uploaded = files.upload()

for fn in uploaded.keys():
    path = fn
    # Load gambar dan ubah ukurannya
    img = image.load_img(path, target_size=(150, 150))
    plt.imshow(img)

    # Preprocessing gambar
    x = image.img_to_array(img) / 255.0
    x = np.expand_dims(x, axis=0)

    # Prediksi kelas
    classes = model_with_aug.predict(x)  # or model.predict(x)
    class_index = np.argmax(classes[0])

    # Menampilkan prediksi
    plt.title(f"Predicted Label: {class_names[class_index]}")
    plt.axis("off")
    plt.show()
